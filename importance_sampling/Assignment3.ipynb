{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZ_n2uxty8S3"
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "This assignment is on neural rendering and shape processing-computer graphics. We provide you with a dataset of 2D icons and corresponding vector graphics. It stems from a line of work on translating low-resolution icons to visually appealing vector forms and was kindly provided by Sheffer et al. for the purpose of this assignment. Detailed assignment instructions are given in the supplemented PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zk5Z_ADTKrgM"
   },
   "source": [
    "# Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cj3ZyUIKrgR"
   },
   "outputs": [],
   "source": [
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import plotting utilities\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define constants\n",
    "import math # needed for math.pi\n",
    "eps = 0.00001\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4795,
     "status": "ok",
     "timestamp": 1580621034460,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "A005CP2tKrga",
    "outputId": "ae25870e-c93c-4060-fa48-7aa81f82d3f0"
   },
   "outputs": [],
   "source": [
    "# download dataset from the web (400 MB file from https://www.cs.ubc.ca/~rhodin/20_CPSC_532R_533R/assignments/EgoCap_nth10.hdf5)\n",
    "dataset_file_name = \"ImagerIcon_subset.hdf5\"\n",
    "import os.path\n",
    "import urllib\n",
    "if not os.path.exists(dataset_file_name):\n",
    "    print(\"Downloading dataset\")\n",
    "    urllib.request.urlretrieve(\"https://www.cs.ubc.ca/~rhodin/20_CPSC_532R_533R/assignments/\"+dataset_file_name, dataset_file_name)\n",
    "    print(\"Done downloading\")\n",
    "else:\n",
    "    print(\"Dataset already present, nothing to be done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "be9FoIVlKrgi"
   },
   "outputs": [],
   "source": [
    "# loading of icon images and vectors\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# loading of the icon dataset \n",
    "class IconDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        super(IconDataset).__init__()\n",
    "        print(\"Loading dataset to memory, can take some seconds\")\n",
    "        with h5py.File(data_file, 'r') as hf:\n",
    "            self.polygon = torch.from_numpy(hf['polygon'][...])\n",
    "            self.imgs  = torch.from_numpy(hf['img'][...])\n",
    "        print(\".. done loading\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.polygon.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # transpose to bring the point dimension in the first place\n",
    "        poly = self.polygon[idx].T.clone()\n",
    "        # negate show icons upright, scale to make networks better behaved\n",
    "        poly[1,:] *= -1\n",
    "        sample = {'img': self.imgs[idx].float()/255, # shape 3 x H x W\n",
    "                  'polygon': poly, # shape 2 x N\n",
    "                  }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1580621037720,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "G6NSgJfDKrgs",
    "outputId": "f105f06e-8cf1-4a63-ff58-c999a1859e89"
   },
   "outputs": [],
   "source": [
    "# load and split the dataset\n",
    "icon = IconDataset(dataset_file_name)\n",
    "print(\"Number of examples in dataset: {}\".format(len(icon)))\n",
    "\n",
    "val_ratio = 0.05\n",
    "val_size = int(len(icon)*val_ratio)\n",
    "indices_val = list(range(0, val_size))\n",
    "indices_train = list(range(val_size, len(icon)))\n",
    "\n",
    "val_set = torch.utils.data.Subset(icon, indices_val)\n",
    "train_set = torch.utils.data.Subset(icon, indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1580621038371,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "Gm7GSDobKrg9",
    "outputId": "f3fa47d2-ced6-426d-9025-a7023e9a2c18"
   },
   "outputs": [],
   "source": [
    "# display dataset examples\n",
    "i = 2\n",
    "img_pil = torchvision.transforms.ToPILImage()(train_set[i]['img'])\n",
    "plt.imshow(img_pil)\n",
    "plt.show()\n",
    "plt.plot(*train_set[i]['polygon'])\n",
    "plt.show()\n",
    "num_points = train_set[i]['polygon'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4L3oE0pHKrhN"
   },
   "outputs": [],
   "source": [
    "# a helper function to map between devices (GPU and CPU)\n",
    "def dict_to_device(dictionary, device):\n",
    "    for k,v in dictionary.items():\n",
    "        dictionary[k] = v.to(device)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmzkEg-RKrha"
   },
   "source": [
    "# Task I: Neural Rendering\n",
    "\n",
    "The first task is about generating an image given a vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYbhK5SAKrhd"
   },
   "outputs": [],
   "source": [
    "# network architecture skeleton\n",
    "class IconGenerator(nn.Module):\n",
    "    def __init__(self, num_points, channels=32, out_channels=3):\n",
    "        super(IconGenerator, self).__init__()\n",
    "\n",
    "        # maps the input points of size (batch dim) x 2 x N\n",
    "        # to a feature map (batch dim) x (#channels) x 2 x 2 \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(in_features=num_points*2, out_features=channels * 2*2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # define a sequence of upsampling, batch norm, ReLu, etc. to map 2x2 features to 32 x 32 images\n",
    "        self.main = nn.Sequential(\n",
    "            # input size: (batch dim) x (#channels) x 2 x 2\n",
    "            # TODO,TASK I: define a sequence of suitable layers. Note, you don't have to use nn.Sequential.\n",
    "            nn.Sigmoid(),\n",
    "            # output size: (batch dim) x (#out_channels=3) x 32 x 32\n",
    "        )\n",
    "      \n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        poly = input_dict['polygon']\n",
    "        batch_size = poly.shape[0]\n",
    "        img_init = self.MLP(poly.view([batch_size,-1]))\n",
    "        img = self.main(img_init.view([batch_size,-1,2,2]))\n",
    "        return {'img': img}\n",
    "network_gen = IconGenerator(num_points).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1580621088074,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "IXykU7hfKrh4",
    "outputId": "043dbbe8-a7fd-400d-eb8d-066f10b5ebd8"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "losses = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 4, shuffle=True)\n",
    "\n",
    "key = \"img\"\n",
    "loss_fn = # TODO loss function\n",
    "fig=plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axes=fig.subplots(1,4)\n",
    "optimizer = optim.Adam(network_gen.parameters(), lr=0.001)\n",
    "for epoch in range(50):\n",
    "    iterator = iter(train_loader)\n",
    "    for i in range(len(train_loader)):\n",
    "        batch = next(iterator)\n",
    "        batch_size = batch[key].shape[0]\n",
    "        dict_to_device(batch, device)\n",
    "\n",
    "        preds = network_gen(batch)\n",
    "        \n",
    "        loss = loss_fn(preds[key], batch[key])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # render the first image in the batch after each epoch\n",
    "    for ax in axes:\n",
    "        ax.cla()\n",
    "    bi = 0 #epoch % batch_size\n",
    "    \n",
    "    points_gt = batch['polygon'][bi].cpu()\n",
    "    axes[0].fill(*points_gt, edgecolor='k', fill=True) # this command closes the loop\n",
    "    axes[0].plot(*points_gt.cpu(),'.') # this command closes the loop\n",
    "    axes[0].set_title('Input polygon')\n",
    "\n",
    "    p_img_pil = torchvision.transforms.ToPILImage()(preds['img'][bi].cpu())\n",
    "    axes[1].imshow(p_img_pil)\n",
    "    axes[1].set_title('Rendered image')\n",
    "\n",
    "    l_img_pil = torchvision.transforms.ToPILImage()(batch['img'][bi].cpu())\n",
    "    axes[2].imshow(l_img_pil)\n",
    "    axes[2].set_title('Ground truth image')\n",
    "\n",
    "    axes[3].plot(losses)\n",
    "    axes[3].set_yscale('log')\n",
    "    axes[3].set_title('Training loss')\n",
    "    axes[3].set_xlabel(\"Gradient iterations\")\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    print(\"Plot after epoch {} (iteration {})\".format(epoch, len(losses)))\n",
    "display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi45RJ26KriI"
   },
   "source": [
    "# Task II: A simple autoencoder, preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h42MLSFmKriM"
   },
   "outputs": [],
   "source": [
    "# simple (but inefficient) polygon autoencoder using fully-connected layers\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, num_points, bottleneck_width):\n",
    "        super(AE, self).__init__()\n",
    "        max_channels = 128\n",
    "        \n",
    "        self.fc1a = nn.Linear(2*num_points, max_channels)\n",
    "        self.fc1c = nn.Linear(max_channels, bottleneck_width)\n",
    "        \n",
    "        self.fc2a = nn.Linear(bottleneck_width, max_channels)\n",
    "        self.fc2c = nn.Linear(max_channels, 2*num_points)\n",
    "\n",
    "    def encode(self, dictionary):\n",
    "        x = dictionary['polygon']\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        h1 = nn.ReLU()(self.fc1a(x))\n",
    "        return self.fc1c(h1)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        batch_size = z.shape[0]\n",
    "        h2 = nn.ReLU()(self.fc2a(z))\n",
    "        h2 = self.fc2c(h2)\n",
    "        \n",
    "        y_NCW = h2.view([batch_size,2,-1])\n",
    "        return {'polygon': y_NCW}\n",
    "\n",
    "    def forward(self, dictionary):\n",
    "        z = self.encode(dictionary)        \n",
    "        poly_dict = self.decode(z)\n",
    "        return poly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsMN8dHmKriU"
   },
   "outputs": [],
   "source": [
    "net_simple = AE(num_points=96, bottleneck_width=10).cuda()\n",
    "num_training_epochs = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1709,
     "status": "ok",
     "timestamp": 1580621261061,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "eLxDw-OGKril",
    "outputId": "657d9796-4e43-4796-e48f-3cbda01cc459"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "losses = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle=True, drop_last=False)\n",
    "print(len(train_loader))\n",
    "key = \"polygon\"\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "fig=plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axes=fig.subplots(1,4)\n",
    "optimizer = optim.Adam(net_simple.parameters(), lr=0.001)\n",
    "for epoch in range(num_training_epochs):\n",
    "    iterator = iter(train_loader)\n",
    "    for i in range(len(train_loader)):\n",
    "        batch = next(iterator)\n",
    "        batch_size = batch[key].shape[0]\n",
    "        dict_to_device(batch, device)\n",
    "        preds = net_simple(batch)\n",
    "        \n",
    "        loss = loss_fn(preds[key], batch[key])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        bi = 0 #epoch % batch_size\n",
    "        for ax in axes:\n",
    "            ax.cla()\n",
    "        points_gt = batch['polygon'][bi].cpu()\n",
    "        axes[0].plot(*points_gt.cpu(),'.') # this command closes the loop\n",
    "        axes[0].plot(*points_gt.cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[0].set_title('Input polygon')\n",
    "\n",
    "        axes[1].plot(*preds['polygon'][bi].detach().cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[1].fill(*preds['polygon'][bi].detach().cpu(), edgecolor='k', fill=True) # this command closes the loop\n",
    "        axes[1].set_title('Output polygon')\n",
    "        \n",
    "        axes[2].fill(*points_gt.cpu(), edgecolor='gray', fill=False) # this command closes the loop\n",
    "        axes[2].plot(*preds['polygon'][bi].detach().cpu(),\".\")\n",
    "        axes[2].set_title('Output pointcloud (GT in gray)')\n",
    "        axes[3].plot(losses)\n",
    "        axes[3].set_yscale('log')\n",
    "        axes[3].set_xlabel(\"Gradient iterations\")\n",
    "        axes[3].set_title('Training loss')    \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        print(\"Plot after epoch {} (iteration {})\".format(epoch, len(losses)))\n",
    "display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCoY5qRcCkY9"
   },
   "source": [
    "# Task III: A simple autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "af0lXCjTKrit"
   },
   "outputs": [],
   "source": [
    "# two-sided loss on the distance to the nearest neighbor\n",
    "def chamfer_distance(pred, label):\n",
    "    batch_size = label.shape[0]\n",
    "    num_points = label.shape[-1]\n",
    "    pred_exp  = pred.view( [batch_size,2,1,-1])\n",
    "    label_exp = label.view([batch_size,2,-1,1])\n",
    "    diff_sq = (pred_exp-label_exp)**2\n",
    "    diff    = torch.sum(diff_sq, dim=1)\n",
    "    min_label, min_label_i = torch.min(diff, dim=-2)\n",
    "    min_pred,  min_pred_i  = torch.min(diff, dim=-1)\n",
    "    return torch.mean(min_label) + torch.mean(min_pred)\n",
    "\n",
    "# functions to roll a tensor along dimension 1 and 2 by n places\n",
    "def roll_1(x, n=1):\n",
    "    return torch.cat((x[:,-n:], x[:,:-n]),dim=1)\n",
    "def roll_2(x, n=1):\n",
    "    return torch.cat((x[:,:,-n:], x[:,:,:-n]),dim=2)\n",
    "\n",
    "# a function that takes two polygons as input and returns the minimum MSE over all possible starting point rotations\n",
    "def roll_invariant_MSE(pred, label):\n",
    "    min_MSE = 999999\n",
    "    # TASK III\n",
    "    return min_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQG5tXg5KrjD"
   },
   "outputs": [],
   "source": [
    "# train this new network, net_simple2, with roll_invariant_MSE to be able to compare results to the MSE training\n",
    "net_simple2 = AE(num_points=96, bottleneck_width=10).cuda()\n",
    "num_training_epochs = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1108,
     "status": "error",
     "timestamp": 1580621889769,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "XfXZgM_qKrjN",
    "outputId": "6fb2021b-78de-45d6-f419-58d8cb9e2470"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "losses = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle=True, drop_last=False)\n",
    "\n",
    "key = \"polygon\"\n",
    "loss_fn = chamfer_distance\n",
    "# loss_fn = roll_invariant_MSE # TODO: use your new loss once \n",
    "fig=plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axes=fig.subplots(1,4)\n",
    "optimizer = optim.Adam(net_simple2.parameters(), lr=0.001)\n",
    "for epoch in range(num_training_epochs):\n",
    "    iterator = iter(train_loader)\n",
    "    for i in range(len(train_loader)):\n",
    "        batch = next(iterator)\n",
    "        batch_size = batch[key].shape[0]\n",
    "        dict_to_device(batch, device)\n",
    "        preds = net_simple2(batch)\n",
    "        \n",
    "        loss = loss_fn(preds[key], batch[key])# + 0.1*angle_prior(preds[key])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        for ax in axes:\n",
    "            ax.cla()\n",
    "        bi = 0\n",
    "        points_gt = batch['polygon'][bi].cpu()\n",
    "        axes[0].plot(*points_gt.cpu(),'.') # this command closes the loop\n",
    "        axes[0].plot(*points_gt.cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[0].set_title('Input polygon')\n",
    "\n",
    "        axes[1].plot(*preds['polygon'][bi].detach().cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[1].fill(*preds['polygon'][bi].detach().cpu(), edgecolor='k', fill=True) # this command closes the loop\n",
    "        axes[1].set_title('Output polygon')\n",
    "        \n",
    "        axes[2].fill(*points_gt.cpu(), edgecolor='gray', fill=False) # this command closes the loop\n",
    "        axes[2].plot(*preds['polygon'][bi].detach().cpu(),\".\")\n",
    "        axes[2].set_title('Output pointcloud (GT in gray)')\n",
    "        axes[3].plot(losses)\n",
    "        axes[3].set_yscale('log')\n",
    "        axes[3].set_xlabel(\"Gradient iterations\")\n",
    "        axes[3].set_title('Training loss')    \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        print(\"Plot after epoch {} (iteration {})\".format(epoch, len(losses)))\n",
    "display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFvbF3HCKrjT"
   },
   "source": [
    "# Task III: Improving the NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhMK5lOYKrjV"
   },
   "outputs": [],
   "source": [
    "# an improved autoencoder that uses *no* fully-connected layer\n",
    "# padding_mode='circular' be careful using it\n",
    "class PolygonAE(nn.Module):\n",
    "    def __init__(self, num_points, bottleneck_width):\n",
    "        super(PolygonAE, self).__init__()\n",
    "        \n",
    "        # TODO, TASK III: Avoid any fully-connected layer in the encoder\n",
    "\n",
    "        # It is OK to maintain the following decoder\n",
    "        self.fc2a = nn.Linear(bottleneck_width, channels_decoder)\n",
    "        self.fc2c = nn.Linear(channels_decoder, 2*num_points)\n",
    "\n",
    "    def encode(self, dictionary):\n",
    "        x_NCW = dictionary['polygon']\n",
    "        \n",
    "        # TODO\n",
    "        \n",
    "        return x_NCW\n",
    "\n",
    "    def decode(self, z):\n",
    "        batch_size = z.shape[0]\n",
    "        h2 = nn.ReLU()(self.fc2a(z))\n",
    "        h2 = self.fc2c(h2)    \n",
    "        y_NCW = h2.view([batch_size,2,-1])\n",
    "        return {'polygon': y_NCW}\n",
    "\n",
    "    def forward(self, dictionary):\n",
    "        z = self.encode(dictionary)        \n",
    "        out_dict = self.decode(z)\n",
    "        return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACmSw5RvKrjm"
   },
   "outputs": [],
   "source": [
    "# train a new network to be able to compare results to the initial training\n",
    "#net_graph = AE(num_points=96, bottleneck_width=10).cuda() # TODO: try this one first by commenting PolygonAE.\n",
    "net_graph = PolygonAE(num_points=96, bottleneck_width=10).cuda() # TODO: uncomment this to replace the simlpe AR with your dedicated one\n",
    "num_training_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3054,
     "status": "ok",
     "timestamp": 1580623764250,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "OOQX4h5xKrjr",
    "outputId": "1a0f037f-b586-42fb-d962-f676b28b95e0"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "losses = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 16, shuffle=True, drop_last=True)\n",
    "\n",
    "def augment_polygon(poly):\n",
    "    # shift starting point\n",
    "    num_points = poly.shape[-1]\n",
    "    random_number = torch.LongTensor(1).random_(0, num_points).item()\n",
    "    poly = roll_2(poly,n=random_number)\n",
    "    return poly\n",
    "\n",
    "key = \"polygon\"\n",
    "loss_fn = roll_invariant_MSE\n",
    "fig=plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axes=fig.subplots(1,4)\n",
    "optimizer = optim.Adam(net_graph.parameters(), lr=0.001)\n",
    "for epoch in range(num_training_epochs):\n",
    "    iterator = iter(train_loader)\n",
    "    for i in range(len(train_loader)):\n",
    "        batch = next(iterator)\n",
    "        batch['polygon'] = augment_polygon(batch['polygon'])\n",
    "        \n",
    "        batch_size = batch[key].shape[0]\n",
    "        dict_to_device(batch, device)\n",
    "        preds = net_graph(batch)\n",
    "        \n",
    "        loss = loss_fn(preds[key], batch[key])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        bi = 0\n",
    "        for ax in axes:\n",
    "            ax.cla()\n",
    "\n",
    "        points_gt = batch['polygon'][bi].cpu()\n",
    "        axes[0].plot(*points_gt.cpu(),'.') # this command closes the loop\n",
    "        axes[0].plot(*points_gt.cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[0].set_title('Input polygon')\n",
    "\n",
    "        axes[1].plot(*preds['polygon'][bi].detach().cpu()[:,0],'.',ms=10,color='red') # mark the first vertext to identify issue\n",
    "        axes[1].fill(*preds['polygon'][bi].detach().cpu(), edgecolor='k', fill=True) # this command closes the loop\n",
    "        axes[1].set_title('Output polygon')\n",
    "        \n",
    "        axes[2].fill(*points_gt.cpu(), edgecolor='gray', fill=False) # this command closes the loop\n",
    "        axes[2].plot(*preds['polygon'][bi].detach().cpu(),\".\")\n",
    "        axes[2].set_title('Output pointcloud (GT in gray)')\n",
    "        axes[3].plot(losses)\n",
    "        axes[3].set_yscale('log')\n",
    "        axes[3].set_xlabel(\"Gradient iterations\")\n",
    "        axes[3].set_title('Training loss') \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        print(\"Plot after epoch {} (iteration {})\".format(epoch, len(losses)))\n",
    "display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzlXYZu3q6tV"
   },
   "source": [
    "# Task IV: Shape space interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1955,
     "status": "ok",
     "timestamp": 1580616993750,
     "user": {
      "displayName": "Helge Rhodin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDx7RzVpx1g9OElwvn2vngvWxd9Sy5QCa98TE4zPg=s64",
      "userId": "13505891862888343836"
     },
     "user_tz": 480
    },
    "id": "NES8ZwQeKrj3",
    "outputId": "4d9310af-e0da-4820-8866-11f5fd5a1e9b"
   },
   "outputs": [],
   "source": [
    "# TODO implement task IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain your findings here."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment3_V07.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
